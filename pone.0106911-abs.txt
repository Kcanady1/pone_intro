Introduction
With the development of photo-electronics, image processing and electronics, computer vision technique is becoming increasingly relevant in industry for on-line inspection, component quality control, solid modeling and dimensional analysis [1]–[3]. Owing to the advantages of non-contact measurement, time efficiency, high flexibility and accuracy, line structured light techniques have found numerous applications [4]–[7]. A basic structured light vision system consists of a camera and a laser projector rigidly fixed with respect to the camera, and the working principle is laser triangulation. During the measurement, the projector projects light stripes on a measured object and the camera obtains images of the light stripes modulated by the depth of the object, then the 3D characteristic information of the measured surface can be acquired from the 2D deformed light stripe image.
The structured light vision system must firstly be fully calibrated before performing any 3D measurement. The goal of calibration is to establish the mapping relationship between the structured light plane and the computer image plane. The traditional approach for calibrating a structured light vision system incorporates two separate stages: camera calibration and projector calibration.
In the camera calibration stage, the intrinsic parameters and extrinsic parameters of camera model are usually calibrated by observing a calibration object whose geometry in 3D space is known with very good precision [8], [9]. Camera calibration can be done very efficiently by using Tsai’s method [10], in which an expensive calibration apparatus is usually required, e.g. a 3-D target. Zhang [11] proposed a flexible new technique for camera calibration by viewing a planar target from different unknown orientations. Accurate calibration points can be easily obtained using this method. Now, it is widely used in the camera calibration.
In the projector calibration stage, the coefficients of the structured light plane equation relative to the camera coordinate frame should be determined. Currently, different approaches for calibrating projector have been proposed in many literatures. In Robert Dewar’s method [12], several thin non-coplanar threads are strained in the space illuminated by a light stripe, and then several bright light dots are obtained as the control points whose 3D coordinates can be measured by means of a theodolite. However, this method requires complicated and expensive equipment, and its accuracy is affected by width restrictions of the light stripe. Huynh [13] has proposed a method, in which the world points on the light stripe plane are generated based on the invariance of the cross-ratio. In the method, a 3D calibration target usually consisting of two or three planes orthogonal to each other is needed for getting the control points, and it is difficult to be manufactured accurately. Recently, a planar target method has been proposed by Zhou [14], in which the intersection points of the light stripe and grids on the target are obtained as the control points. Since the quantity of the grids is limited, the number of control points is still not enough for calibrating projector accurately. Sometimes, to generate the intersection points of the grids and the light stripes, the orientation of the target is not flexible and random in the space. To make the system convenient to use on-site and under limited space, Wei [15] has proposed a novel 1D target-based calibration method for structured light vision sensors by randomly viewing a 1D target from different unknown orientations positioned within the field of view. Similar to Zhou’s method, the control points obtained are few in the method. Besides the above methods, there are other methods of calibrating a structured light vision system being presented in the literature [16]–[18]. But all these methods mainly have the following drawbacks: 1. it is difficult to generate large number of control points; 2. some methods require an elaborate and expensive calibration apparatus; 3. some methods are not suitable for field calibration.
In this paper, a novel approach for line structured light vision system calibration is proposed, in which a planar target with a square pattern is used. The proposed method only requires the camera to observe the planar target shown at a few (at least two) different orientations, and simultaneously the light stripe should be projected onto the target. Subpixel center localizations of the light stripe on the target are detected as the control points, which are sufficient to improve calibration accuracy. The paper is organized as follows. In the Method Section, a camera model is given first inspired by the work of Zhang, and then the detailed procedure of projector calibration is described, which includes working out the target plane, extracting center of the light stripe and fitting the structured light plane. Experimental studies are given in the next Section. The paper ends with conclusions.
